{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOFctJk7IH/eOOaVM1FhwX2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OpticalFenixer96/EJercicios_del_libro/blob/main/Ejercicio1.2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Ejercicio 1.2**"
      ],
      "metadata": {
        "id": "6dKEL2AmksSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Suppose that we use perceptron to detect spam messages. Let´s say that each email message is represented by the frequency of ocurrence of the keywords, and the output is +1 if the message is considered spam. \n",
        "\n",
        "a) Can you think of some keywords that will end up with a large positive weight in the perceptron?. \n",
        "\n",
        "b) How about keywords that will get negative weight? \n",
        "\n",
        "c) What parameter in the perceptron directly affects how many border-line messages end up being classified as spam?"
      ],
      "metadata": {
        "id": "4jR4rRP6ky4-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "a) En el contexto de detectar mensajes  spam usando un perceptron, algunas palabras o frases se pueden configurar para que tengan un mayor peso lo que indicaria una mayor probabilidad de que el correo evaluado corresponda a un correo de tipo SPAM\n",
        "\n",
        "Ejemplos correspondientes a posibles indicativos de un correo SPAM pueden ser:\n",
        "\n",
        "- Su cuenta bancaria ah sido seleccionada para un premio.\n",
        "- Ah ganado la loteria.\n",
        "- Viaje Gratis.\n",
        "- Su envio tiene un valor adeudado.\n",
        "- Se encuentra hospotalizado\n",
        "- El principe de \n"
      ],
      "metadata": {
        "id": "zGnaWygwlvDA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "b) Algunas palabras que se pueden considerar con un peso negativo, serian correos que no fueran SPAM. \n",
        "\n",
        "Algunos ejemplos podrian ser:\n",
        " - Tarea.\n",
        " - Proyecto.\n",
        " - Universidad."
      ],
      "metadata": {
        "id": "ZYgR_OeTnlPf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "c)  El parámetro en el perceptrón que afecta directamente cuántos mensajes que se encuentran en la frontera terminan siendo clasificados como SPAM es el término de sesgo (bias). El sesgo actúa como un límite de decisión para la salida del perceptrón. Si el sesgo se establece en un valor negativo grande, más mensajes en la frontera serán clasificados como SPAM. Por el contrario, si el sesgo se establece en un valor positivo grande, menos mensajes en la frontera serán clasificados como SPAM."
      ],
      "metadata": {
        "id": "RLndM3Sjoh-I"
      }
    }
  ]
}